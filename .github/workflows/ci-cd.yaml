name: CI/CD Pipeline

on:
  push:
    branches: [main, develop]
    paths:
      - 'src/**'
      - 'tests/**'
      - 'pyproject.toml'
      - '.github/workflows/**'
  pull_request:
    branches: [main]
  schedule:
    # Run model training weekly on Sunday at midnight
    - cron: '0 0 * * 0'
  workflow_dispatch:
    inputs:
      run_training:
        description: 'Run model training'
        required: false
        default: 'false'

env:
  PYTHON_VERSION: '3.10'
  MLFLOW_TRACKING_URI: ${{ secrets.MLFLOW_TRACKING_URI }}
  GITHUB_TOKEN_API: ${{ secrets.GH_API_TOKEN }}

jobs:
  lint:
    name: Code Quality Check
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
      
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install ruff black isort mypy
      
      - name: Run ruff linter
        run: ruff check src/ --output-format=github
      
      - name: Run black check
        run: black --check src/
      
      - name: Run isort check
        run: isort --check-only src/
      
      - name: Run type checking
        run: mypy src/ --ignore-missing-imports --no-error-summary || true

  test:
    name: Run Tests
    runs-on: ubuntu-latest
    needs: lint
    steps:
      - uses: actions/checkout@v4
      
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'
      
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -e ".[dev]"
      
      - name: Run tests with coverage
        run: |
          pytest tests/ -v --cov=src --cov-report=xml --cov-report=html
      
      - name: Upload coverage report
        uses: codecov/codecov-action@v4
        with:
          file: ./coverage.xml
          fail_ci_if_error: false

  data-validation:
    name: Data Quality Validation
    runs-on: ubuntu-latest
    needs: test
    if: github.event_name == 'schedule' || github.event.inputs.run_training == 'true'
    steps:
      - uses: actions/checkout@v4
      
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'
      
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -e .
      
      - name: Run data validation
        run: |
          python -c "
          from src.data_validation import create_data_quality_validator
          from src.etl import ETLProcessor
          import json
          
          etl = ETLProcessor()
          validator = create_data_quality_validator()
          
          repos = etl.list_available_repositories()[:5]
          results = {}
          
          for repo in repos:
              try:
                  data = etl.load_repository_data(repo)
                  report = validator.validate(data)
                  results[repo] = {
                      'is_valid': report.is_valid,
                      'warnings': len(report.warnings),
                      'anomalies': len(report.anomalies)
                  }
              except Exception as e:
                  results[repo] = {'error': str(e)}
          
          print(json.dumps(results, indent=2))
          
          failed = [r for r, v in results.items() if not v.get('is_valid', True)]
          if failed:
              print(f'Warning: {len(failed)} repositories have data quality issues')
          "

  model-training:
    name: Train and Evaluate Models
    runs-on: ubuntu-latest
    needs: data-validation
    if: github.event_name == 'schedule' || github.event.inputs.run_training == 'true'
    steps:
      - uses: actions/checkout@v4
      
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'
      
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -e .
      
      - name: Train models
        run: |
          python -c "
          from src.model_selection import create_auto_model_selector
          from src.model_registry import create_model_registry
          from src.etl import ETLProcessor
          
          etl = ETLProcessor()
          selector = create_auto_model_selector()
          registry = create_model_registry()
          
          repos = etl.list_available_repositories()[:3]
          
          for repo in repos:
              try:
                  data = etl.load_repository_data(repo)
                  
                  if len(data) < 52:
                      print(f'Skipping {repo}: insufficient data')
                      continue
                  
                  # Select best model
                  best_model, results = selector.select_best_model(
                      data, 
                      target_column='commits'
                  )
                  
                  print(f'{repo}: Best model = {results[\"best_model_type\"]}')
                  print(f'  SMAPE: {results[\"best_smape\"]:.2f}')
                  
                  # Register model
                  registry.register_model(
                      model=best_model,
                      model_name=f'{repo}_commits',
                      model_type=results['best_model_type'],
                      metrics={'smape': results['best_smape']},
                      parameters=results.get('best_params', {})
                  )
                  
              except Exception as e:
                  print(f'Error training {repo}: {e}')
          "
      
      - name: Upload model artifacts
        uses: actions/upload-artifact@v4
        with:
          name: model-registry
          path: model_registry/
          retention-days: 30

  build-docker:
    name: Build Docker Image
    runs-on: ubuntu-latest
    needs: test
    if: github.ref == 'refs/heads/main'
    steps:
      - uses: actions/checkout@v4
      
      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3
      
      - name: Build Docker image
        run: |
          docker build -t bigmlops:${{ github.sha }} .
          docker build -t bigmlops:latest .
      
      - name: Run container tests
        run: |
          docker run --rm bigmlops:latest python -c "
          from src.etl import ETLProcessor
          from src.model_engine import train_predict_recursive
          print('Container test passed!')
          "

  deploy-staging:
    name: Deploy to Staging
    runs-on: ubuntu-latest
    needs: [build-docker, model-training]
    if: github.ref == 'refs/heads/main' && (github.event_name == 'schedule' || github.event.inputs.run_training == 'true')
    environment: staging
    steps:
      - uses: actions/checkout@v4
      
      - name: Download model artifacts
        uses: actions/download-artifact@v4
        with:
          name: model-registry
          path: model_registry/
      
      - name: Deploy to staging
        run: |
          echo "Deploying to staging environment..."
          # Add deployment commands here
          # docker-compose -f compose.staging.yaml up -d

  integration-tests:
    name: Integration Tests
    runs-on: ubuntu-latest
    needs: deploy-staging
    if: github.ref == 'refs/heads/main'
    steps:
      - uses: actions/checkout@v4
      
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
      
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install requests pytest
      
      - name: Run integration tests
        run: |
          echo "Running integration tests..."
          # Add integration test commands here
          # pytest tests/integration/ -v

  deploy-production:
    name: Deploy to Production
    runs-on: ubuntu-latest
    needs: integration-tests
    if: github.ref == 'refs/heads/main'
    environment: production
    steps:
      - uses: actions/checkout@v4
      
      - name: Download model artifacts
        uses: actions/download-artifact@v4
        with:
          name: model-registry
          path: model_registry/
      
      - name: Deploy to production
        run: |
          echo "Deploying to production environment..."
          # Add production deployment commands here
          # docker-compose -f compose.yaml up -d
